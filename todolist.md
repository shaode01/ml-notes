1. xgboost，rf，GBDT三者的区别，以及带来模型的提升多大，为什么不采用其他方法，是否比较过这三者的应用场景
2. 线性回归与LR的原理与区别，LR的损失函数，以及为什么采用sigmod函数
3. svm的原理以及对偶问题，为什么采用对偶，解释一下对偶
    1. 手推SVM的loss function
    2. SVM的kernel的选择
    3. 比较logistic回归和SVM
4. 三种决策树的分裂标准，决策树停止生成的条件，如何防止过拟合
5. 过拟合的常见方法
6. boosting和bagging的原理与区别，常见的代表有哪些
7. 讲一下AUC，在什么情况下采用AUC值，以及召回率与准确率，如何选择合适的评价指标
8. 比较logistic回归和SVM
9. PCA及其实现（给定n个D维表述的数据点，问怎么实现）
10. 手写一下决策树中信息增益的公式，说说信息增益代表一个什么意思（数据内的混乱度，也叫作信息熵），某个特征的信息增益对总体信息增益的偏离数值比较大，就把它看做是分类特征（ID3算法）
